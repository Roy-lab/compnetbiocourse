{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8765e39",
   "metadata": {},
   "source": [
    "## Step 1. Learning the structure of Bayesian networks\n",
    "In this notebook we will try a simple Bayesian network inference algorithm and review concepts of consensus structures and evaluation. We will do this using the [pgmpy python suite](https://pgmpy.org/index.html) suite. This notebook assumes that the data files are already in your current path. In particular, if you did `ls` in your current folder, you should be able to see `data`. These required files for this homework have been placed in `/home/medinfo/bmi775/bmi775-f22/hw1_files`\n",
    "\n",
    "We will first import pgmpy into the Jupyter environment. The notebook was tested with pgmpy version 0.1.19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pgmpy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08971d2c",
   "metadata": {},
   "source": [
    "The structure learning will use a simple Greedy Hill climbing search algorithm implemented in the `HillClimbSearch` module using the `K2Score`. We will next import these two modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b927fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import HillClimbSearch, K2Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95a913",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd665dd",
   "metadata": {},
   "source": [
    "Next we will load the data. This dataset is from a single cell RNA-seq experiment in yeast from [this paper](https://doi.org/10.1371/journal.pbio.2004050). This dataset measures gene expression of ~6k genes in 163 cells. We have cleaned up and reduced the dataset to ~40 genes across 163 cells. We binarized the data, where 1 means the gene is ON and 0 means the gene is OFF. We have further subsampled the data into 50 subsamples. We will first load in one subsample, `dataset0.txt`. There are 50 such subsamples that we already generated for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=pd.read_csv(\"data/gasch_n100_subsamples/dataset0.txt\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da0397b",
   "metadata": {},
   "source": [
    "Let's look at the contents of this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1245569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dfec18",
   "metadata": {},
   "source": [
    "This has gene names on the first row and the number of rows correspond to the number of samples and the number of columns are the nodes/genes/random variables in our Bayesian network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded3638",
   "metadata": {},
   "source": [
    "### Learning one Bayesian network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c965ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_method = K2Score(data=ss) # this will set the dataset of the score\n",
    "est = HillClimbSearch(data=ss) # this will set the dataset for the search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade8017",
   "metadata": {},
   "source": [
    "Now we are ready to learn the Bayesian network. We will let a node to have max 4 parents and will set max iterations of inference to be 10000. The output `estimated_model` is our Bayesian network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675a4a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_model = est.estimate(scoring_method=scoring_method, max_indegree=4, max_iter=int(1e4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692d35ba",
   "metadata": {},
   "source": [
    "Let's visualize what we learned. We will use the `networkx` and `matplotlib` packages for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "pos=nx.nx_agraph.graphviz_layout(estimated_model);\n",
    "nx.draw(estimated_model,pos=pos,with_labels=True,node_size=500,font_size=8,alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804a6e8",
   "metadata": {},
   "source": [
    "Save the network to an output path. Here we will put it in the `bnets` folder in the current path that contains the running notebook. Note that Bayesian networks learned from pgmpy are all based on `networkx` and many of the functionalities are inherited in the Bayesian networks we learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3404091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path('bnets').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "nx.write_edgelist(estimated_model,'bnets/net0.txt', data=False, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee4d761",
   "metadata": {},
   "source": [
    "### Step 2. Evaluation of the inferred network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a92f0b",
   "metadata": {},
   "source": [
    "The \"imperfect\" ground truth for these networks are in`data/networks/groundtruth_n100.txt`. We will use the `compareGraphs` program to see how well we learned the network. In particular execute your version of `compareGraphs` and report the precision, recall, and F-score. For example, assuming `compareGraphs` is in the current path, you can obtain the precision, recall, F-score as follows:\n",
    "    \n",
    "`./compareGraphs data/networks/groundtruth_n100.txt bnets/net0.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a73952",
   "metadata": {},
   "source": [
    "### Step 3. Consensus graph creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d025d8b9",
   "metadata": {},
   "source": [
    "We will generate a consensus graph by applying the Bayesian network learning process to different number of subsamples. We will write these networks into the same `bnets` folder. The code below is for generating 5 networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8019ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in range(0,5):\n",
    "    ss = pd.read_csv(\"data/gasch_n100_subsamples/dataset\"+str(id)+\".txt\")\n",
    "    scoring_method = K2Score(data=ss) \n",
    "    est = HillClimbSearch(data=ss)\n",
    "    model1 = est.estimate(scoring_method=scoring_method, max_indegree=4, max_iter=int(1e4)) \n",
    "    nx.write_edgelist(model1,'bnets/net'+str(id)+'.txt', data=False, delimiter='\\t')  \n",
    "    print('Done with dataset' + str(id) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e79e3f4",
   "metadata": {},
   "source": [
    "Once we have generated these networks, we can create a consensus using your `makeConsensus` code written in problem 4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
