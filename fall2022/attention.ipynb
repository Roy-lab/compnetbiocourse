{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention examples\n",
    "Anthony Gitter  \n",
    "October 18, 2022  \n",
    "Explore the attention calculations from the lecture slides\n",
    "\n",
    "Recall from [Vaswani et al. Attention is All you Need](https://papers.nips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html)\n",
    "> An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
    "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
    "of the values, where the weight assigned to each value is computed by a compatibility function of the\n",
    "query with the corresponding key\n",
    "\n",
    "The goal of attention and multi-headed self-attention is to learn good word embeddings based on word-word relationships in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention warmup\n",
    "First we show the calcuations for the mammal attention examples in the slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the query vector. This could be a query matrix with multiple queries as shown later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammal = np.array([8.7, 3.2, 4.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially define the key vectors individually so we can see how they correspond to the keys in the slides. These must have the same length as the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitten = np.array([9.1, 1.0, 2.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lizard = np.array([0.1, 7.5, 4.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "salmon = np.array([1.3, 5.5, 8.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "whale = np.array([7.6, 2.4, 4.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wolf = np.array([8.5, 2.7, 2.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and inspect the scaling factor we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7320508075688772\n"
     ]
    }
   ],
   "source": [
    "scaling = np.sqrt(len(mammal))\n",
    "print(scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all of the keys into the keys matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_names = ['kitten', 'lizard', 'salmon', 'whale', 'wolf']\n",
    "animals = np.stack([kitten, lizard, salmon, whale, wolf], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.1, 1. , 2.1],\n",
       "       [0.1, 7.5, 4.3],\n",
       "       [1.3, 5.5, 8.2],\n",
       "       [7.6, 2.4, 4. ],\n",
       "       [8.5, 2.7, 2.7]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the query-key dot products before scaling and taking the softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90.98, 42.5 , 62.53, 90.2 , 93.66])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mammal@animals.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52.52732749, 24.53738644, 36.10171233, 52.07699428, 54.07462621])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mammal@animals.T/np.sqrt(len(mammal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the similarity weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.57823895e-01 1.10228985e-13 1.16042942e-08 1.00599432e-01\n",
      " 7.41576662e-01]\n"
     ]
    }
   ],
   "source": [
    "weights = softmax(mammal@animals.T/scaling)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the values that correspond to each key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([[3.4,1.3,0.4,9.8], # furry\n",
    "                  [7.5,3.9,4.1,0.2], # scaly\n",
    "                  [8.3,2.8,2.3,0.1], # slippery\n",
    "                  [1.6,8.4,9.9,3.4], # huge\n",
    "                  [2.2,9.4,8.7,1.1]]) # ferocious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the final ouput value for our query `mammal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.32902909 8.02102694 7.51078092 2.70444657]\n"
     ]
    }
   ],
   "source": [
    "output = weights@values\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it with a different query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reptile = np.array([2.1, 9.9, 1.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.25436708e-13 9.98297480e-01 1.70251120e-03 1.47297680e-09\n",
      " 7.33251915e-09]\n"
     ]
    }
   ],
   "source": [
    "weights = softmax(reptile@animals.T/scaling)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.50136196 3.89812728 4.09693552 0.19982976]\n"
     ]
    }
   ],
   "source": [
    "output = weights@values\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we have a query matrix instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.7 3.2 4.1]\n",
      " [2.1 9.9 1.6]]\n"
     ]
    }
   ],
   "source": [
    "query = np.stack([mammal, reptile], axis=0)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.57823895e-01 1.10228985e-13 1.16042942e-08 1.00599432e-01\n",
      "  7.41576662e-01]\n",
      " [5.25436708e-13 9.98297480e-01 1.70251120e-03 1.47297680e-09\n",
      "  7.33251915e-09]]\n"
     ]
    }
   ],
   "source": [
    "# Take the softmax over each row, not the entire matrix\n",
    "weights = softmax(query@animals.T/scaling, axis=1)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated mammal embedding: [2.32902909 8.02102694 7.51078092 2.70444657]\n",
      "Updated reptile embedding: [7.50136196 3.89812728 4.09693552 0.19982976]\n"
     ]
    }
   ],
   "source": [
    "# First row is the updated value for 'mammal'\n",
    "# Second row is the updated value for 'reptile'\n",
    "animal_output = weights@values\n",
    "print(f'Updated mammal embedding: {animal_output[0]}')\n",
    "print(f'Updated reptile embedding: {animal_output[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention function\n",
    "Define an `attention` function to simplify these calculations. The outputs are the same as the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(queries, keys, values):\n",
    "    # Assume all inputs are 2D matrices\n",
    "    assert queries.ndim == 2\n",
    "    assert keys.ndim == 2\n",
    "    assert values.ndim == 2\n",
    "    \n",
    "    scale = np.sqrt(len(queries[0]))\n",
    "    # Take the softmax over each row, not the entire matrix\n",
    "    weights = softmax(queries@keys.T/scale, axis=1)\n",
    "    return weights@values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated mammal embedding: [2.32902909 8.02102694 7.51078092 2.70444657]\n",
      "Updated reptile embedding: [7.50136196 3.89812728 4.09693552 0.19982976]\n"
     ]
    }
   ],
   "source": [
    "# The output from the attention function matches the output above\n",
    "animal_output2 = attention(query, animals, values)\n",
    "print(f'Updated mammal embedding: {animal_output2[0]}')\n",
    "print(f'Updated reptile embedding: {animal_output2[1]}')\n",
    "\n",
    "# Test that animal_output and animal_output2 are very similar\n",
    "assert np.isclose(animal_output, animal_output2).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-attention\n",
    "It is not very useful to calculate self-attention yet without introducing multi-headed attention, but we can see how to use the `attention` function to do it.\n",
    "\n",
    "We can compute self-attention between the animals and themselves.  The animals act as the queries, key, and values.  We obtain and updated representation of each animal based on its similarity to the other animals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_self_output = attention(animals, animals, animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the original animal embeddings and the updated animal embeddings. They have not changed much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitten\toriginal [9.1 1.  2.1] and updated [8.97593633 1.33207376 2.22679209] embeddings\n",
      "lizard\toriginal [0.1 7.5 4.3] and updated [0.99832734 6.00278776 7.21956386] embeddings\n",
      "salmon\toriginal [1.3 5.5 8.2] and updated [1.29999732 5.50000446 8.1999913 ] embeddings\n",
      "whale\toriginal [7.6 2.4 4. ] and updated [8.47958483 2.29781683 2.78497945] embeddings\n",
      "wolf\toriginal [8.5 2.7 2.7] and updated [8.6669283  2.1237928  2.54756204] embeddings\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(animal_names)):\n",
    "    print(f'{animal_names[i]}\\toriginal {animals[i]} and updated {animal_self_output[i]} embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-headed self-attention\n",
    "Self-attention is useful in its multi-headed form when the same original embeddings are transformed by a different trainable $W^Q$, $W^K$, and $W^V$ to project the embeddings before the attention calculations. These $W$ matrices are updated during stochastic gradient descent-based training, so the model can learn how to adjust the embeddings to obtain meaningful self-attention calculations in order to update the embeddings.\n",
    "\n",
    "Here the $W$ are made up and not meaningful but can illustrate the calculations. We also only demonstrate a single attention head, whereas multi-headed attention would have many heads and many different traininable copies of the $W$ matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(775)\n",
    "w_q = np.random.rand(3,2)\n",
    "w_k = np.random.rand(3,2)\n",
    "w_v = np.random.rand(3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random projection, which would typically be trained and meaningful. Reduces the animal embedding dimension from 3 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37573502, 0.24683143],\n",
       "       [0.24614648, 0.38234858],\n",
       "       [0.03510655, 0.89775264]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three different $W$ matrices give three different 2-dimensional representations of the animals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.73905893, 4.51379518],\n",
       "       [2.03463026, 6.75263382],\n",
       "       [2.13013489, 9.78536968],\n",
       "       [3.58676392, 6.38456605],\n",
       "       [3.95313086, 5.55434048]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals@w_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.96561697,  2.8778713 ],\n",
       "       [ 9.18598435,  6.01216844],\n",
       "       [12.06063652,  5.9414747 ],\n",
       "       [10.5822552 ,  4.0030275 ],\n",
       "       [10.27859483,  4.02849108]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals@w_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.18065523, 5.67484759],\n",
       "       [4.44534671, 5.48037139],\n",
       "       [7.14038542, 7.99398679],\n",
       "       [3.76938987, 6.79569809],\n",
       "       [2.87492446, 6.39373835]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals@w_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-headed self-attention calls the `attention` function with the new projections of the animal embeddings. In a Transformer, we would need to multiply this by another trainable matrix $W^O$ to map back from 2 to 3 dimensions, or if we had several attention heads from the concatenated outputs back to 3 dimensions. Here, we leave the output in 2 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_multi_output = attention(animals@w_q, animals@w_k, animals@w_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using random $W$ matrices was a bad idea! These updated embeddings don't mean anything. But we can see how the operations connect together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitten\toriginal [9.1 1.  2.1] and updated [7.1384725  7.99233055] embeddings\n",
      "lizard\toriginal [0.1 7.5 4.3] and updated [7.08124031 7.93886421] embeddings\n",
      "salmon\toriginal [1.3 5.5 8.2] and updated [7.08371845 7.94113509] embeddings\n",
      "whale\toriginal [7.6 2.4 4. ] and updated [7.1378387  7.99162334] embeddings\n",
      "wolf\toriginal [8.5 2.7 2.7] and updated [7.13919142 7.99289749] embeddings\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(animal_names)):\n",
    "    print(f'{animal_names[i]}\\toriginal {animals[i]} and updated {animal_multi_output[i]} embeddings')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
